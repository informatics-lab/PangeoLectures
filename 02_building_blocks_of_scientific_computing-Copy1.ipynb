{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "alien-publisher",
   "metadata": {},
   "source": [
    "# Section 2: The building blocks of a Scientific Computing Platform\n",
    "\n",
    "In the first section we introduced some typical users of a scientific compute platform and typical tasks that such users may wish to perform on such a platform. We then looked at 2 models for delivering the compute capability that users require, the desktop model and the cluster model. Each of these has its advantages and disadvantages. The next step is to consider how we could design and build a platform that combines the advantages of different systems and removes (as much as possible) the disadvtages.  In this notebook we will discuss those principles by looking at the key goals of what we'll call the *Pangeo model of Scientific Computing*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assisted-complexity",
   "metadata": {},
   "source": [
    "## Goal 1 - An interactive platform that scales\n",
    "\n",
    "A key tension between the desktop and cluster models of computing that we identified was the tradeoffs between compute which enables an interactive workflow and compute which can operate at scale. The Pangeo model should offer compute with an interactive workflow that can scale to the size of the problem you are working on. The development of cloud computing and associated technologies has gone a long way to making this a realisable goal. Let's consider some of the aspects of what cloud computing has mader easier or possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "representative-tractor",
   "metadata": {},
   "source": [
    "### Affordable data storage\n",
    "\n",
    "Compute capacity is not very useful without matched data storage capacity which can be accessed quickly, easily and cheaply. Cloud computing providers offer huge storage capacity at affordable prices that located close (physically asnd topologically) to the compute.\n",
    "\n",
    "It is important to remember that this storage though is structuted differently to the hard disks in the desktop or cluster which we may be used to. Some important traits of cloud storage\n",
    "* high latency - responses to requests for data take longer than for a local disk on  desktop as this is networked storage akin to that found on a cluster.\n",
    "* distributed - the storage and access mechanisms are highlly parallelised for robustness and to meet demand. This means one can usually achieve very high data throughputs.\n",
    "* The distributed nature of the storage means that you can run into issues around consistency. See [CAP Theorem](https://en.wikipedia.org/wiki/CAP_theorem)\n",
    "\n",
    "This different structure means to make optimal use of the advtages and minimise the disadvtages of cloud storage, we need to use different formats for our data that are **cloud-optimised**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colonial-utility",
   "metadata": {},
   "source": [
    "### Distributed compute\n",
    "\n",
    "It was mentioned previously that part of what made the desktop model work was *Moore's Law*, which described the rate at which the speed of silicon processors increased. More accurately it actually described the rate at which the desnity of transitors in integrated circuits increased. This mostly translated into increased speed of processing withoutn having to change anything about the code that one had written. Due to hard physical limits, this is no longer true. Instead, the latest chips can do more operations in parallel, and in order to get the best performance out of them our code needs to be execute in parallel as much as possible. \n",
    "\n",
    "Luckily, many of the common operations in scientific computing are highly parallelisable and so such operations scale well conceptually, provided we write our code appropriately, as well as the underlying tools being written approriately for parallel execution. \n",
    "\n",
    "There are multiple levels of distribution:\n",
    "* *Task distribution* - completely separate operation that do not depend on one another than can be executed in parallel. This may be on separate piceces of data. This is relatively easy to support and was the main way of distribtuing compute previously. Examples: calculating a mean on separate datasets, calculating min and max on a dataset.\n",
    "\n",
    "* *Data distribution* - individual operations on a dataset, where the operation can be performed separately on different parts of the dataset. This sort of distribution has long been a part of weather models, but has up until recently been less common outside of HPC. Only as datasets have become too large to fit on a single machine has this gained importance. The dataset is split into chunks and calculations on each chunk can be done separately, on separate CPU cores, or nodes or even in competely different data centres (though this is of course inefficient!). \n",
    "\n",
    "This distributed nature of compute is another factor in creating **cloud-optimised** datasets, so our data  facilitates our exploitation of this massively distributed computed resource rather than hinders it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rapid-punch",
   "metadata": {},
   "source": [
    "### Scalable compute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handled-physiology",
   "metadata": {},
   "source": [
    "### Elastic compute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparative-thickness",
   "metadata": {},
   "source": [
    "## Goal 2 - Reproducible Research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shaped-publisher",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "opposed-tunnel",
   "metadata": {},
   "source": [
    "## Goal 3 - Shareable research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chief-customs",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "authentic-blake",
   "metadata": {},
   "source": [
    "## Goal 4 - Cost effective compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worthy-title",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "substantial-evanescence",
   "metadata": {},
   "source": [
    "## Goal 5 - Separation of concerns\n",
    "Allowing researchers to focus on the goals of their research project and spend minimal time worrying about the underlying enabling infrastructure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inside-temperature",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-turning",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "placed-security",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
